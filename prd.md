# Notion 뉴스 자동화 시스템 - 제품 요구사항 문서 (PRD)

## 1. 제품 개요

### 1.1 목적
Notion을 데이터베이스로 활용하여 뉴스를 자동으로 수집하고 정리하는 시스템을 제공합니다. 사용자가 수동으로 뉴스를 수집하고 정리하는 시간을 절약하고, 생활 패턴을 더욱 체계적으로 관리할 수 있도록 지원합니다.

### 1.2 핵심 가치
- **자동화**: RSS 피드를 통해 뉴스를 자동으로 수집하여 Notion에 저장
- **중앙화**: 모든 뉴스를 하나의 Notion 데이터베이스에서 관리
- **정기 실행**: 스케줄러를 통해 정기적으로 자동 실행
- **확장성**: 다른 자동화 기능을 쉽게 추가할 수 있는 구조

### 1.3 대상 사용자
- 뉴스를 정기적으로 읽고 정리하고 싶은 개인
- 생활 패턴을 루틴화하고 싶은 사용자
- Notion을 활용한 정보 관리 시스템을 구축하고 싶은 사용자

## 2. 기능 요구사항

### 2.1 핵심 기능

#### 2.1.1 RSS 피드 수집
- **설명**: 여러 RSS 피드에서 뉴스 기사를 자동으로 수집
- **입력**: RSS 피드 URL 목록
- **출력**: 구조화된 뉴스 데이터 (제목, 링크, 설명, 출처, 날짜)
- **RSS 피드란?**: RSS(Really Simple Syndication)는 뉴스 사이트에서 최신 기사 목록을 제공하는 표준 형식입니다
- **구체적인 예시**:
  - CNN: `https://rss.cnn.com/rss/edition.rss`
  - BBC News: `https://feeds.bbci.co.uk/news/rss.xml`
  - New York Times: `https://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml`
  - 네이버 정치: `https://news.naver.com/main/rss/section.naver?sid=100`
  - 네이버 경제: `https://news.naver.com/main/rss/section.naver?sid=101`
  - 네이버 IT/과학: `https://news.naver.com/main/rss/section.naver?sid=105`
- **요구사항**:
  - 여러 피드를 동시에 수집 가능
  - 네트워크 오류 시 재시도 로직
  - 파싱 오류 처리

#### 2.1.2 중복 제거
- **설명**: 동일한 뉴스 기사가 여러 피드에서 수집될 경우 중복 제거
- **방법**: 링크 URL을 기준으로 중복 판단
- **향후 개선**: 제목 유사도 기반 중복 감지

#### 2.1.3 Notion 데이터베이스 저장
- **설명**: 수집한 뉴스를 Notion 데이터베이스에 자동으로 저장
- **저장 항목**:
  - 제목 (Title) - 뉴스 기사 제목
  - 링크 (URL) - 원본 기사 링크 (클릭하여 바로 이동 가능)
  - 설명 (Rich Text, 선택사항) - 기사 요약 또는 본문 일부
  - 출처 (Rich Text, 선택사항) - 뉴스 소스 (예: CNN, BBC 등)
  - 날짜 (Date, 선택사항) - 기사 발행일
- **사용자 경험 최적화**:
  - **데이터베이스 뷰**: 갤러리 뷰, 보드 뷰, 타임라인 뷰 등 다양한 방식으로 확인 가능
  - **정렬**: 기본적으로 최신순 정렬 (날짜 기준)
  - **필터**: 출처별, 날짜별 필터링 가능
  - **레이아웃**: Notion의 강력한 데이터베이스 기능을 활용하여 한눈에 정리된 형태로 표시
  - **모바일 접근**: Notion 모바일 앱을 통해 언제 어디서나 뉴스 확인 가능
- **요구사항**:
  - Notion API rate limit 준수
  - 저장 실패 시 에러 처리 및 로깅

#### 2.1.4 스케줄링
- **설명**: 정기적으로 뉴스 수집 작업을 자동 실행
- **구현 방식**: GitHub Actions를 통한 클라우드 기반 스케줄링
- **기본 설정**: 하루 2회 (오전 9시, 오후 6시, 한국 시간 기준)
- **커스터마이징**: GitHub Actions workflow 파일에서 Cron 표현식 변경 가능
- **스케줄러란?** (비개발자용 설명)
  - 스케줄러는 정해진 시간에 자동으로 뉴스를 수집하는 기능입니다
  - 비유: 매일 아침 9시와 저녁 6시에 뉴스를 모아서 Notion에 저장하는 자동 도우미
  - GitHub Actions를 사용하면 PC가 꺼져 있어도 자동으로 작동합니다
  - GitHub 서버에서 실행되므로 별도의 서버나 PC를 켜둘 필요가 없습니다
- **장점**:
  - PC가 꺼져 있어도 자동 실행 (GitHub 서버에서 실행)
  - 무료 (공개 저장소 기준)
  - 실행 로그 자동 기록 (GitHub Actions 탭에서 확인)
  - 별도 서버 관리 불필요
- **요구사항**:
  - GitHub 저장소에 코드 푸시
  - GitHub Secrets에 환경 변수 설정
  - 실행 로그 기록

### 2.2 부가 기능

#### 2.2.1 설정 관리
- RSS 피드 목록 관리 (`src/config/feeds.ts`)
- 환경 변수를 통한 API 키 및 데이터베이스 ID 관리
- 스케줄 설정 커스터마이징

#### 2.2.2 에러 처리
- 네트워크 오류 처리
- Notion API 오류 처리
- RSS 파싱 오류 처리
- 부분 실패 시에도 다른 피드 수집 계속 진행

#### 2.2.3 로깅
- 수집 시작/완료 로그
- 저장 성공/실패 로그
- 에러 상세 정보 기록

## 3. 기술 스택 및 아키텍처

### 3.1 기술 스택

#### 3.1.1 언어 및 런타임
- **TypeScript**: 타입 안정성을 위한 정적 타입 언어
- **Node.js**: 서버 사이드 실행 환경

#### 3.1.2 주요 라이브러리
- **@notionhq/client**: Notion API 공식 클라이언트
- **rss-parser**: RSS 피드 파싱
- **node-cron**: 스케줄링
- **dotenv**: 환경 변수 관리

#### 3.1.3 개발 도구
- **tsx**: TypeScript 실행 및 개발 모드
- **TypeScript**: 컴파일러

#### 3.1.4 배포 및 스케줄링
- **GitHub Actions**: 클라우드 기반 자동 실행 (무료, PC가 꺼져 있어도 작동)
- **node-cron**: 로컬 개발/테스트용 (선택사항)

### 3.2 아키텍처

```
┌─────────────────────────────────────────┐
│           Entry Points                  │
│  - src/index.ts (스케줄러)              │
│  - src/scripts/news-collector.ts        │
└──────────────┬──────────────────────────┘
               │
┌──────────────▼──────────────────────────┐
│        Services Layer                   │
│  - news-collector.ts                    │
│    • collectNewsFromRSS()               │
│    • saveNewsToNotion()                 │
│    • collectAndSaveNews()              │
└──────────────┬──────────────────────────┘
               │
┌──────────────▼──────────────────────────┐
│        Library Layer                    │
│  - notion-client.ts                     │
│    • createPage()                       │
│    • getDatabase()                      │
└──────────────┬──────────────────────────┘
               │
┌──────────────▼──────────────────────────┐
│        Config Layer                     │
│  - env.ts (환경 변수)                   │
│  - feeds.ts (RSS 피드 설정)             │
└─────────────────────────────────────────┘
```

### 3.3 데이터 흐름

```
RSS 피드 URL 목록
    ↓
RSS 파서 (rss-parser)
    ↓
뉴스 아이템 배열
    ↓
중복 제거 (링크 기준)
    ↓
Notion API 클라이언트
    ↓
Notion 데이터베이스
```

## 4. 사용자 시나리오

### 4.1 초기 설정 시나리오

**사용자**: 개발자/일반 사용자

**목표**: Notion 뉴스 자동화 시스템을 처음 설정

**단계**:
1. 프로젝트 클론 및 의존성 설치
2. Notion Integration 생성 및 API 키 발급
3. Notion에서 데이터베이스 생성 및 속성 설정
4. Integration을 데이터베이스에 연결
5. GitHub 저장소 생성 및 코드 푸시
6. GitHub Secrets에 환경 변수 설정 (NOTION_API_KEY, NOTION_DATABASE_ID)
7. GitHub Actions workflow 파일 확인 (`.github/workflows/news-collector.yml`)
8. RSS 피드 목록 설정 (`src/config/feeds.ts`)
9. 테스트 실행 (GitHub Actions에서 수동 트리거 또는 첫 스케줄 실행 대기)
10. GitHub Actions 탭에서 실행 로그 확인

**성공 기준**: 
- 뉴스가 Notion 데이터베이스에 정상적으로 저장됨
- GitHub Actions에서 정기적으로 자동 실행됨
- PC가 꺼져 있어도 자동 실행됨

### 4.2 일상 사용 시나리오

**사용자**: 일반 사용자

**목표**: 정기적으로 뉴스를 자동으로 수집하고 정리

**단계**:
1. GitHub Actions가 설정된 시간에 자동 실행 (PC가 꺼져 있어도 작동)
2. RSS 피드에서 뉴스 수집
3. 중복 제거
4. Notion 데이터베이스에 저장
5. GitHub Actions 탭에서 실행 로그 확인
6. Notion 모바일 앱 또는 웹에서 뉴스 확인

**성공 기준**: 
- 매일 정해진 시간에 뉴스가 자동으로 수집되어 저장됨
- PC가 꺼져 있어도 정상 작동
- 모바일에서도 Notion 앱을 통해 뉴스 확인 가능

### 4.3 수동 실행 시나리오

**사용자**: 일반 사용자

**목표**: 스케줄러를 기다리지 않고 즉시 뉴스 수집

**단계**:
1. GitHub Actions에서 "Run workflow" 버튼 클릭 (수동 실행)
2. 또는 로컬에서 `pnpm run news` 실행
3. 뉴스 수집 및 저장 완료 확인

**성공 기준**: 
- 명령어 실행 즉시 뉴스가 수집되어 저장됨
- GitHub Actions에서 수동 실행도 가능

## 5. 성공 지표

### 5.1 기능적 지표
- **수집 성공률**: 전체 피드 중 성공적으로 수집된 비율 (목표: 95% 이상)
- **저장 성공률**: 수집된 뉴스 중 Notion에 성공적으로 저장된 비율 (목표: 99% 이상)
- **중복 제거율**: 중복된 뉴스가 제대로 제거되는지 확인

### 5.2 성능 지표
- **수집 시간**: 10개 피드 기준 5분 이내
- **API 호출 효율**: Notion API rate limit 준수
- **메모리 사용량**: 안정적인 메모리 사용

### 5.3 사용자 경험 지표
- **설정 시간**: 초기 설정 완료까지 30분 이내
- **에러 발생 빈도**: 주당 에러 발생 1회 이하
- **로그 가독성**: 에러 발생 시 원인 파악 가능

## 6. 제약사항 및 고려사항

### 6.1 기술적 제약사항
- **Notion API Rate Limit**: 초당 3회 요청 제한
- **RSS 피드 가용성**: 일부 피드는 접근 제한이 있을 수 있음
- **네트워크 의존성**: 인터넷 연결 필수

### 6.2 보안 고려사항
- API 키는 환경 변수로 관리 (`.env` 파일은 Git에 커밋하지 않음)
- Notion Integration은 최소 권한 원칙 적용

### 6.3 데이터 품질
- RSS 피드의 품질에 따라 수집 데이터의 품질이 좌우됨
- 일부 피드는 설명이나 날짜 정보가 없을 수 있음

## 7. 향후 확장 계획

### 7.0 배포 옵션 (현재 구현)

#### 7.0.1 GitHub Actions (권장 - 현재 구현)
- [x] GitHub Actions workflow 설정
- [x] Cron 스케줄 기반 자동 실행
- [x] 환경 변수 Secrets 관리
- [ ] 실행 알림 (이메일, 슬랙)
- [ ] 실행 통계 대시보드

#### 7.0.2 Docker 배포 (선택사항)
- [ ] Dockerfile 작성
- [ ] Docker Compose 설정
- [ ] 클라우드 서버 배포 가이드 (AWS, Google Cloud 등)
- **참고**: Docker는 서버 비용이 발생하므로 개인용으로는 GitHub Actions가 더 적합

### 7.1 단기 개선 (1-2개월)
- [ ] 에러 처리 강화 및 재시도 로직
- [ ] 데이터베이스 기반 중복 체크
- [ ] 구조화된 로깅 시스템
- [ ] 배치 처리로 성능 개선

### 7.2 중기 개선 (3-6개월)
- [ ] 뉴스 내용 요약 기능 (AI 활용)
- [ ] 카테고리 자동 분류
- [ ] 중요도 점수 계산
- [ ] 웹 대시보드 제공
- [ ] 알림 시스템 (이메일, 슬랙)

### 7.3 장기 확장 (6개월 이상)
- [ ] 다른 뉴스 소스 지원 (News API, Google News 등)
- [ ] 다중 데이터베이스 지원
- [ ] 플러그인 시스템
- [ ] 다른 자동화 기능 추가
  - 독서 목록 관리
  - 지출 내역 자동 기록
  - 일기 자동 작성
  - 할 일 목록 관리
  - 습관 추적

## 8. 위험 요소 및 대응 방안

### 8.1 위험 요소
1. **Notion API 변경**: Notion이 API를 변경하거나 제한할 경우
2. **RSS 피드 중단**: 주요 뉴스 소스의 RSS 피드 제공 중단
3. **네트워크 장애**: 지속적인 네트워크 문제로 수집 실패
4. **데이터 중복**: 중복 제거 로직이 완벽하지 않을 수 있음

### 8.2 대응 방안
1. **API 변경 대응**: 정기적인 API 문서 확인 및 업데이트
2. **다양한 소스**: 여러 뉴스 소스를 활용하여 단일 소스 의존성 감소
3. **재시도 로직**: 네트워크 오류 시 자동 재시도
4. **중복 체크 개선**: 데이터베이스 기반 중복 체크로 정확도 향상

## 9. 참고 자료

### 9.1 문서
- [Notion API 문서](https://developers.notion.com/)
- [RSS Parser 문서](https://www.npmjs.com/package/rss-parser)
- [Node Cron 문서](https://www.npmjs.com/package/node-cron)
- [GitHub Actions 문서](https://docs.github.com/en/actions)
- [GitHub Actions Cron 스케줄 가이드](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule)

### 9.2 관련 프로젝트
- Notion API 공식 예제
- RSS 피드 파싱 라이브러리

## 10. 버전 히스토리

### v1.0.0 (현재)
- 기본 뉴스 수집 기능
- RSS 피드 파싱
- Notion 데이터베이스 저장
- GitHub Actions 기반 자동 스케줄링 (PC가 꺼져 있어도 작동)

---

**문서 작성일**: 2024년
**최종 수정일**: 2024년
**작성자**: Notionauto 개발팀

